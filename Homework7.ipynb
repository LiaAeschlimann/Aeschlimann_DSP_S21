{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7\n",
    "## Exercise - Conceptuals\n",
    "### 3a) Explain how k-fold cross-validation is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> K-fold CV involves randomly dividing the set of observations into k groups, or folds, of approximately equal size. The first fold is treated as a validation set (test set), and the method is fit on the remaining k − 1 folds. We then calculate the mean squared error on the observations in the held-out fold.\n",
    "This procedure is repeated k times; each time, a different group of observations is treated as a validation set. This process results in k estimates of the test error, MSE1, MSE2,...,MSEk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b) General advantages & disadvantages\n",
    "\n",
    "### The validation set approach - advantages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Although we dont know which of the curves, derived from different test MSE estimate for each of the regression models consider results in the smallest validation set MSE - we do know if for example a linear fit is adequate for our data. That's helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The validation set approach - disadvantages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The variability of the validation estimates of the test error rate can be very high, depending on which observations are included in the training set and which observations are included in the validation set.\n",
    "\n",
    "> Only a subset of the observations — those included in the training set rather than in the validation set — are used to fit the model. This suggests that the validation set error rate may tend to overestimate the test error rate for the model fit on the entire data set.\n",
    "\n",
    "> We dont know which of the curves, derived from different test MSE estimate for each of the regression models consider results in the smallest validation set MSE - we only know if for example a linear fit is adequate for our data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The LOOCV approach - advantages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It provides an approximately unbiased estimate for the test error. It has far less bias than the validation set approach. \n",
    "\n",
    "> The LOOCV approach tends not to overestimate the test error rate as much as the validation set approach does.\n",
    "\n",
    "> when applied repeatedly it will always yield the same results: there is no randomness in the training/vali- dation set splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The LOOCV approach - disadvantages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LOOCV has the potential to be expensive (in time) to implement, since the model\n",
    "has to be fit n times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# and now to the actual question...\n",
    "### What are the advantages and disadvantages of k-fold cross- validation relative to: \n",
    "### validation set approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (+) There is typically some variability in the CV estimates as a result of the variability in how the observations are divided into ten folds. But this variability is typically much lower than the variability in the test error estimates that results from the validation set approach. \n",
    "\n",
    "> (+) K-fold CV doesn't overestimate the test error rate, compared to the validation set approach. \n",
    "\n",
    "> (-) Can be more timeconsuming, when choosing a high k.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the advantages and disadvantages of k-fold cross- validation relative to: \n",
    "### LOOCV:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (+) LOOCV requires fitting the statistical learning method n times. This has the potential to be computationally expensive. But cross-validation is a very general approach that can be applied to almost any statistical learning method. CV requires fitting the learning procedure only ten times (if k = 10), which may be much more feasible.\n",
    "\n",
    "\n",
    "> (+) / (-) The main advantage of k-fold is the bias-variance trade-off: k-fold CV often gives more accurate estimates of the test error rate than does LOOCV. But LOOCV is less biased since there are as many training sets as observations. However, LOOCV has higher variance than k-fold CV does with k < n.\n",
    "Compared to the validation set approach, LOOCV provides an approximately unbiased estimate for the test error/ less bias than the validation set approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Applied\n",
    "### 7a) Fit a logistic regressionmodel that predicts Direction using Lag1 and Lag2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/sc/hyjdb_fs3q9bfhvw0h8h4t9m0000gn/T//RtmpjqfK6N/downloaded_packages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Year</th><th scope=col>Lag1</th><th scope=col>Lag2</th><th scope=col>Lag3</th><th scope=col>Lag4</th><th scope=col>Lag5</th><th scope=col>Volume</th><th scope=col>Today</th><th scope=col>Direction</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1990</td><td> 0.816</td><td> 1.572</td><td>-3.936</td><td>-0.229</td><td>-3.484</td><td>0.1549760</td><td>-0.270</td><td>Down</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1990</td><td>-0.270</td><td> 0.816</td><td> 1.572</td><td>-3.936</td><td>-0.229</td><td>0.1485740</td><td>-2.576</td><td>Down</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1990</td><td>-2.576</td><td>-0.270</td><td> 0.816</td><td> 1.572</td><td>-3.936</td><td>0.1598375</td><td> 3.514</td><td>Up  </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1990</td><td> 3.514</td><td>-2.576</td><td>-0.270</td><td> 0.816</td><td> 1.572</td><td>0.1616300</td><td> 0.712</td><td>Up  </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1990</td><td> 0.712</td><td> 3.514</td><td>-2.576</td><td>-0.270</td><td> 0.816</td><td>0.1537280</td><td> 1.178</td><td>Up  </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1990</td><td> 1.178</td><td> 0.712</td><td> 3.514</td><td>-2.576</td><td>-0.270</td><td>0.1544440</td><td>-1.372</td><td>Down</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 9\n",
       "\\begin{tabular}{r|lllllllll}\n",
       "  & Year & Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume & Today & Direction\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & 1990 &  0.816 &  1.572 & -3.936 & -0.229 & -3.484 & 0.1549760 & -0.270 & Down\\\\\n",
       "\t2 & 1990 & -0.270 &  0.816 &  1.572 & -3.936 & -0.229 & 0.1485740 & -2.576 & Down\\\\\n",
       "\t3 & 1990 & -2.576 & -0.270 &  0.816 &  1.572 & -3.936 & 0.1598375 &  3.514 & Up  \\\\\n",
       "\t4 & 1990 &  3.514 & -2.576 & -0.270 &  0.816 &  1.572 & 0.1616300 &  0.712 & Up  \\\\\n",
       "\t5 & 1990 &  0.712 &  3.514 & -2.576 & -0.270 &  0.816 & 0.1537280 &  1.178 & Up  \\\\\n",
       "\t6 & 1990 &  1.178 &  0.712 &  3.514 & -2.576 & -0.270 & 0.1544440 & -1.372 & Down\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 9\n",
       "\n",
       "| <!--/--> | Year &lt;dbl&gt; | Lag1 &lt;dbl&gt; | Lag2 &lt;dbl&gt; | Lag3 &lt;dbl&gt; | Lag4 &lt;dbl&gt; | Lag5 &lt;dbl&gt; | Volume &lt;dbl&gt; | Today &lt;dbl&gt; | Direction &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1990 |  0.816 |  1.572 | -3.936 | -0.229 | -3.484 | 0.1549760 | -0.270 | Down |\n",
       "| 2 | 1990 | -0.270 |  0.816 |  1.572 | -3.936 | -0.229 | 0.1485740 | -2.576 | Down |\n",
       "| 3 | 1990 | -2.576 | -0.270 |  0.816 |  1.572 | -3.936 | 0.1598375 |  3.514 | Up   |\n",
       "| 4 | 1990 |  3.514 | -2.576 | -0.270 |  0.816 |  1.572 | 0.1616300 |  0.712 | Up   |\n",
       "| 5 | 1990 |  0.712 |  3.514 | -2.576 | -0.270 |  0.816 | 0.1537280 |  1.178 | Up   |\n",
       "| 6 | 1990 |  1.178 |  0.712 |  3.514 | -2.576 | -0.270 | 0.1544440 | -1.372 | Down |\n",
       "\n"
      ],
      "text/plain": [
       "  Year Lag1   Lag2   Lag3   Lag4   Lag5   Volume    Today  Direction\n",
       "1 1990  0.816  1.572 -3.936 -0.229 -3.484 0.1549760 -0.270 Down     \n",
       "2 1990 -0.270  0.816  1.572 -3.936 -0.229 0.1485740 -2.576 Down     \n",
       "3 1990 -2.576 -0.270  0.816  1.572 -3.936 0.1598375  3.514 Up       \n",
       "4 1990  3.514 -2.576 -0.270  0.816  1.572 0.1616300  0.712 Up       \n",
       "5 1990  0.712  3.514 -2.576 -0.270  0.816 0.1537280  1.178 Up       \n",
       "6 1990  1.178  0.712  3.514 -2.576 -0.270 0.1544440 -1.372 Down     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following objects are masked from Weekly (pos = 3):\n",
      "\n",
      "    Direction, Lag1, Lag2, Lag3, Lag4, Lag5, Today, Volume, Year\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"ISLR\")\n",
    "library(ISLR)\n",
    "head(Weekly)\n",
    "set.seed(1)\n",
    "attach(Weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Direction ~ Lag1 + Lag2, family = binomial, data = Weekly)\n",
       "\n",
       "Deviance Residuals: \n",
       "   Min      1Q  Median      3Q     Max  \n",
       "-1.623  -1.261   1.001   1.083   1.506  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  0.22122    0.06147   3.599 0.000319 ***\n",
       "Lag1        -0.03872    0.02622  -1.477 0.139672    \n",
       "Lag2         0.06025    0.02655   2.270 0.023232 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1496.2  on 1088  degrees of freedom\n",
       "Residual deviance: 1488.2  on 1086  degrees of freedom\n",
       "AIC: 1494.2\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>0.221224054272484</dd><dt>Lag1</dt><dd>-0.0387222224735869</dd><dt>Lag2</dt><dd>0.06024830276829</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 0.221224054272484\n",
       "\\item[Lag1] -0.0387222224735869\n",
       "\\item[Lag2] 0.06024830276829\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   0.221224054272484Lag1\n",
       ":   -0.0387222224735869Lag2\n",
       ":   0.06024830276829\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)        Lag1        Lag2 \n",
       " 0.22122405 -0.03872222  0.06024830 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm1 = glm(Direction~Lag1+Lag2, data=Weekly, family=binomial)\n",
    "summary(glm.fit)\n",
    "coef(glm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b) Fit a logistic regressionmodel that predicts Direction using Lag1 and Lag2, using all but the first observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Direction ~ Lag1 + Lag2, family = binomial, data = Weekly[-1, \n",
       "    ])\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.6258  -1.2617   0.9999   1.0819   1.5071  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  0.22324    0.06150   3.630 0.000283 ***\n",
       "Lag1        -0.03843    0.02622  -1.466 0.142683    \n",
       "Lag2         0.06085    0.02656   2.291 0.021971 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1494.6  on 1087  degrees of freedom\n",
       "Residual deviance: 1486.5  on 1085  degrees of freedom\n",
       "AIC: 1492.5\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm2 <- glm(Direction ~ Lag1 + Lag2, data = Weekly[-1, ], family = binomial)\n",
    "summary(glm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7c) Predict the direction of the first observation. Was it correctly classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in if (!se.fit) {:\n",
      "“Bedingung hat Länge > 1 und nur das erste Element wird benutzt”\n",
      "Warning message in if (se.fit) list(fit = predictor, se.fit = se, df = df, residual.scale = sqrt(res.var)) else predictor:\n",
      "“Bedingung hat Länge > 1 und nur das erste Element wird benutzt”\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>fit</dt><dd>TRUE</dd><dt>se.fit</dt><dd>FALSE</dd><dt>residual.scale</dt><dd>TRUE</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[fit] TRUE\n",
       "\\item[se.fit] FALSE\n",
       "\\item[residual.scale] TRUE\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "fit\n",
       ":   TRUEse.fit\n",
       ":   FALSEresidual.scale\n",
       ":   TRUE\n",
       "\n"
      ],
      "text/plain": [
       "           fit         se.fit residual.scale \n",
       "          TRUE          FALSE           TRUE "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> TRUE"
      ],
      "text/latex": [
       "\\textbf{1:} TRUE"
      ],
      "text/markdown": [
       "**1:** TRUE"
      ],
      "text/plain": [
       "   1 \n",
       "TRUE "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict.glm(glm2, Weekly[1,],Direction=\"Up\"|Lag1, Lag2, type=\"response\") > 0.5\n",
    "predict.glm(glm2, Weekly[1,], type=\"response\") > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No, it's not correctly classified: The prediction was \"Up\" but it actually goes \"Down\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7d) Write a for loop from i =1 to i = n, and perform following steps:\n",
    "- Fit a logistic regression model using all but the ith obser- vation to predict Direction using Lag1 and Lag2.\n",
    "- Compute the posterior probability of the market moving up for the ith observation.\n",
    "- Use the posterior probability for the ith observation in order to predict whether or not the market moves up.\n",
    "- Determine whether or not an error was made in predicting the direction for the ith observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "490"
      ],
      "text/latex": [
       "490"
      ],
      "text/markdown": [
       "490"
      ],
      "text/plain": [
       "[1] 490"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = rep(0, dim(Weekly)[1])\n",
    "for (i in 1:(dim(Weekly)[1])) {\n",
    "    glm3 = glm(Direction~Lag1+Lag2, data=Weekly[-i,], family=binomial)\n",
    "    check_up = predict.glm(glm3, Weekly[i,], type =\"response\") > 0.5\n",
    "    true_up = Weekly[i,]$Direction == \"Up\"\n",
    "    if (check_up != true_up) \n",
    "    count[i] = 1\n",
    "    else\n",
    "        0\n",
    "    }\n",
    "sum(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7e) Take the average of the n numbers obtained in (d)iv in order to obtain the LOOCV estimate for the test error. Comment on the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.45"
      ],
      "text/latex": [
       "0.45"
      ],
      "text/markdown": [
       "0.45"
      ],
      "text/plain": [
       "[1] 0.45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(mean(count),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The LOOCV approach gives an estimated test error rate of 45%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9a) Provide an estimate for the population mean of medv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t506 obs. of  14 variables:\n",
      " $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n",
      " $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n",
      " $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n",
      " $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n",
      " $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n",
      " $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...\n",
      " $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n",
      " $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...\n",
      " $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n",
      " $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n",
      " $ black  : num  397 397 393 395 397 ...\n",
      " $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n",
      " $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...\n"
     ]
    }
   ],
   "source": [
    "library(boot)\n",
    "library(MASS)\n",
    "attach(Boston)\n",
    "str(Boston)\n",
    "set.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "22.533"
      ],
      "text/latex": [
       "22.533"
      ],
      "text/markdown": [
       "22.533"
      ],
      "text/plain": [
       "[1] 22.533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu <- mean(Boston$medv)\n",
    "round (mu, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9b) Provide an estimate of the standard error of ˆμ. Interpret this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.409"
      ],
      "text/latex": [
       "0.409"
      ],
      "text/markdown": [
       "0.409"
      ],
      "text/plain": [
       "[1] 0.409"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu_se <- sd(Boston$medv)/sqrt(length(Boston$medv))\n",
    "round(mu_se, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9c) Now estimate the standard error of ˆμ using the bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre class=language-r><code>function (data, index) \n",
       "return(mean(data[index]))</code></pre>"
      ],
      "text/latex": [
       "\\begin{minted}{r}\n",
       "function (data, index) \n",
       "return(mean(data{[}index{]}))\n",
       "\\end{minted}"
      ],
      "text/markdown": [
       "```r\n",
       "function (data, index) \n",
       "return(mean(data[index]))\n",
       "```"
      ],
      "text/plain": [
       "function(data, index)\n",
       "    return(mean(data[index]))\n",
       "<bytecode: 0x7fa8754b9df8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = medv, statistic = alpha.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "    original      bias    std. error\n",
       "t1* 22.53281 0.007650791   0.4106622"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha.fn = function(data, index)\n",
    "    return(mean(data[index]))\n",
    "bootstrap <- boot(medv, alpha.fn, R=1000) \n",
    "\n",
    "alpha.fn\n",
    "bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When comparing the standard error from the population mean (0.409) and the one of bootstrap (0.402), one can say, that they are almost the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9d) Provide a 95% con- fidence interval for the mean of medv & compare to t-test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "21.7280498"
      ],
      "text/latex": [
       "21.7280498"
      ],
      "text/markdown": [
       "21.7280498"
      ],
      "text/plain": [
       "[1] 21.72805"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "23.3375702"
      ],
      "text/latex": [
       "23.3375702"
      ],
      "text/markdown": [
       "23.3375702"
      ],
      "text/plain": [
       "[1] 23.33757"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  Boston$medv\n",
       "t = 55.111, df = 505, p-value < 2.2e-16\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 21.72953 23.33608\n",
       "sample estimates:\n",
       "mean of x \n",
       " 22.53281 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_ci <- 22.53281-2*0.4023801\n",
    "upper_ci <- 22.53281+2*0.4023801\n",
    "\n",
    "lower_ci\n",
    "upper_ci\n",
    "\n",
    "t.test(Boston$medv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The mean of the bootstrap estimate was 22.533 with a CI of [21.728; 23.338], where as the results from the t-test show following: mean estimate of 22.533 with CI of [21.730; 23.336]. They are almost the same. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9e) Provide an estimate, ˆμmed, for the median value of medv in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "21.2"
      ],
      "text/latex": [
       "21.2"
      ],
      "text/markdown": [
       "21.2"
      ],
      "text/plain": [
       "[1] 21.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "medv.med = median(medv)\n",
    "medv.med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9f) Estimate the standard error of the median using the bootstrap - Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre class=language-r><code>function (data, index) \n",
       "return(median(data[index]))</code></pre>"
      ],
      "text/latex": [
       "\\begin{minted}{r}\n",
       "function (data, index) \n",
       "return(median(data{[}index{]}))\n",
       "\\end{minted}"
      ],
      "text/markdown": [
       "```r\n",
       "function (data, index) \n",
       "return(median(data[index]))\n",
       "```"
      ],
      "text/plain": [
       "function(data, index)\n",
       "    return(median(data[index]))\n",
       "<bytecode: 0x7fa86cd770d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = medv, statistic = alpha.fn2, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "    original  bias    std. error\n",
       "t1*     21.2 -0.0386   0.3770241"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha.fn2 = function(data, index)\n",
    "    return(median(data[index]))\n",
    "bootstrap2 <- boot(medv, alpha.fn2, R=1000) \n",
    "\n",
    "alpha.fn2\n",
    "bootstrap2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The standard error of mu computed with bootstrap is 0.388. The mean of 21.2 is the same as computed with median().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9g) Provide an estimate for the tenth percentile of medv in Boston suburbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>10%:</strong> 12.75"
      ],
      "text/latex": [
       "\\textbf{10\\textbackslash{}\\%:} 12.75"
      ],
      "text/markdown": [
       "**10%:** 12.75"
      ],
      "text/plain": [
       "  10% \n",
       "12.75 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "medv.0.1 = quantile(medv, c(0.1))\n",
    "medv.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9h) Estimate the standard error of ˆμ0.1 using bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre class=language-r><code>function (data, index) \n",
       "return(quantile(data[index], 0.1))</code></pre>"
      ],
      "text/latex": [
       "\\begin{minted}{r}\n",
       "function (data, index) \n",
       "return(quantile(data{[}index{]}, 0.1))\n",
       "\\end{minted}"
      ],
      "text/markdown": [
       "```r\n",
       "function (data, index) \n",
       "return(quantile(data[index], 0.1))\n",
       "```"
      ],
      "text/plain": [
       "function(data, index)\n",
       "    return(quantile(data[index], 0.1))\n",
       "<bytecode: 0x7fa8718cea20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = medv, statistic = alpha.fn3, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "    original  bias    std. error\n",
       "t1*    12.75  0.0186   0.4925766"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha.fn3 = function(data, index)\n",
    "    return(quantile(data[index], 0.1))\n",
    "bootstrap3 <- boot(medv, alpha.fn3, R=1000) \n",
    "\n",
    "alpha.fn3\n",
    "bootstrap3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The standard error of ˆμ0.1 computed with bootstrap is 0.493. The mean of 12.75 is the same as computed with quantile()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
